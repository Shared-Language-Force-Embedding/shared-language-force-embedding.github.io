---
layout: page
title: Results
permalink: /results/
---

<h2>Metrics</h2>
    
<ul>
    <li><strong>Force Profile Accuracy (FPAcc):</strong> Measures how closely the predicted force profile \( \hat{x}_f \) matches the ground truth \( x_f \) using Mean Squared Error (MSE).  
        $$
        \text{FPAcc} = \text{MSE}(\hat{x}_f, x_f)
        $$
    </li>
    <li><strong>Force Direction Accuracy (FDAcc):</strong> Evaluates directional alignment between predicted impulse \( \hat{J}(T) \) and ground truth impulse \( J(T) \) using cosine similarity.  
        $$
        \text{FDAcc} = \frac{\hat{J}(T) \cdot J(T)}{||\hat{J}(T)|| \cdot ||J(T)||}
        $$
    </li>
    <li><strong>Modifier Similarity (ModSim):</strong> Cosine similarity between the predicted modifier \( \hat{w}_m \) and the ground truth \( w_m \) using SBERT embeddings \( E \).  
        $$
        \text{ModSim} = \frac{E(\hat{w}_m) \cdot E(w_m)}{||E(\hat{w}_m)|| \cdot ||E(w_m)||}
        $$
    </li>
    <li><strong>Direction Similarity (DirSim):</strong> Cosine similarity between predicted direction words \( \hat{w}_d \) and ground truth \( w_d \).  
        $$
        \text{DirSim} = \frac{E(\hat{w}_d) \cdot E(w_d)}{||E(\hat{w}_d)|| \cdot ||E(w_d)||}
        $$
    </li>
    <li><strong>Full Phrase Similarity (PhraseSim):</strong> Average of \( \text{ModSim} \) and \( \text{DirSim} \).  
        $$
        \text{PhraseSim} = \frac{1}{2} \left(\text{ModSim} + \text{DirSim} \right)
        $$
    </li>
</ul>

<h2>Baseline Models</h2>
<ul>
    <li>$\text{SVM/KNN}$: Uses SVM to classify force signals into phrases and KNN to predict force profiles from phrases.</li>
    <li>$\text{DMLP}_B$: Direct MLP mapping between force profiles and binary phrase vectors without a shared latent space.</li>
    <li>$\text{DMLP}_G$: Direct MLP mapping between force profiles and GloVe-embedded phrases without a shared latent space.</li>
    <li>$\text{DAE}_B$ (Ours): Dual autoencoder with binary phrase vectors.</li>
    <li>$\text{DAE}G$ (Ours): Dual autoencoder with GloVe embeddings.</li>
</ul>

<h2>Experiments</h2>
<p>To evaluate the effectiveness of our cross-modality embedding framework, we conducted three main experiments:</p>
<ol>
    <li><strong>In-Distribution Evaluation:</strong> The dataset was randomly split into 90% training and 10% testing sets. Models were trained and tested on the same distribution of force–phrase pairs and averaged across 30 independent seeds to reduce variability in the results.</li>
    
    <li><strong>Out-of-Distribution Modifiers:</strong> To test generalization, we systematically held out one modifier word (e.g., “slowly”) from the training set while keeping it in the test set. This experiment measured how well the models handled unseen adverbial variations in force descriptions.</li>
    
    <li><strong>Out-of-Distribution Directions:</strong> Similar to the modifier experiment, we excluded a single direction word (e.g., “up”) from training and evaluated the model’s ability to generalize to new directional inputs. This tested whether the models could infer force trajectories for previously unseen movement directions.</li>
</ol>


<h2>Overall Results</h2>
<p>Our framework outperforms baseline models in both force-to-language and language-to-force translation, demonstrating the effectiveness of a shared latent space.</p>

{% include overall_results.html %}

<h2>Analysis</h2>
<p>Our results showed that the dual autoencoder (DAE) models significantly outperformed baseline approaches in both force-to-language and language-to-force translation. The DAE models achieved 20-30% better performance than simpler SVM and MLP-based baselines, demonstrating that a shared latent space effectively captures the bidirectional relationship between physical force and linguistic descriptions.</p>

<p>Additionally, the models successfully generalized to unseen modifiers and directions, particularly when using GloVe embeddings, which improved force profile reconstruction. However, we observed a trade-off between force reconstruction accuracy and linguistic precision: the GloVe-based model (\( \text{DAE}_G \)) was better at estimating realistic force trajectories, while the binary phrase vector model (\( \text{DAE}_B \)) provided more precise textual descriptions.</p>

<p>These findings confirm that integrating force and language into a unified representation enhances natural human-robot communication, with different representation choices offering advantages depending on whether force accuracy or linguistic fidelity is prioritized.</p>

<h2>Additional Results</h2>

<h3>Translation Examples</h3>

<p>Example predictions from both $\text{DAE}_B$ and $\text{DAE}_G$ variants for corresponding force profile&mdash;phrase pairs. We generated 10 different 90-10 training-test splits, ensuring that the union of all test sets covers the full dataset. Each data point was randomly assigned to one of 10 bins, with each bin serving as a distinct test set in one of the splits. The model was trained on the remaining 9 bins and evaluated on the held-out test bin. The examples below show model predictions for cases where the corresponding force-phrase pair was not explicitly seen during training.</p>

<!-- Load jQuery and DataTables -->
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script src="https://cdn.datatables.net/1.11.5/js/jquery.dataTables.min.js"></script>
<link rel="stylesheet" href="https://cdn.datatables.net/1.11.5/css/jquery.dataTables.min.css">

<strong>Phrase-To-Force Trials</strong>

<p>Corresponding force profile and phrase pairs collected from the Phrase-To-Force procedure.</p>

<!-- Dropdown for Modifiers -->
<label for="searchModifier_phrase2force">Filter by Modifier:</label>
<select id="searchModifier_phrase2force">
    <option value="">All</option>
    <option value="(None)">None</option>
    {% for modifier in site.data.unique_phrase_parts.unique_modifiers %}
        {% if modifier != "" %}
            <option value="{{ modifier }}">{{ modifier }}</option>
        {% endif %}
    {% endfor %}
</select>

<!-- Dropdown for Directions -->
<label for="searchDirection_phrase2force">Filter by Direction:</label>
<select id="searchDirection_phrase2force">
    <option value="">All</option>
    {% for direction in site.data.unique_phrase_parts.unique_directions %}
        {% if direction != "" %}
            <option value="{{ direction }}">{{ direction }}</option>
        {% endif %}
    {% endfor %}
</select>

<!-- Data Table -->
<table id="dataTable_phrase2force" class="display">
    <thead>
        <tr>
            <th>User ID</th>
            <th>Trial #</th>
            <th>Phrase Text</th>
            <th>Modifier</th>
            <th>Direction</th>
            <th>Trial Card</th>
        </tr>
    </thead>
    <tbody>
        {% for row in site.data.phrase2force_corpus %}
        <tr>
            <td>{{ row.user_id }}</td>
            <td>{{ row.trial_number }}</td>
            <td>{{ row.phrase_text }}</td>
            <td>{{ row.adverb | default: "(None)" }}</td>
            <td>{{ row.direction }}</td>
            <td>
                <a href="#" class="load-trial-card" 
                   data-type="Phrase2Force" 
                   data-user="{{ row.user_id }}" 
                   data-trial="{{ row.trial_number }}" 
                   data-phrase="{{ row.phrase_text }}" 
                   data-modifier="{{ row.adverb | default: '(None)' }}" 
                   data-direction="{{ row.direction }}">
                    View
                </a>
            </td>
        </tr>
        {% endfor %}
    </tbody>
</table>

<!-- Placeholder for dynamically loaded trial cards -->
<div id="trialCardContainer"></div>

<script>
$(document).ready(function () {
    var phrase2forceTable = $('#dataTable_phrase2force').DataTable();
    var force2phraseTable = $('#dataTable_force2phrase').DataTable();

    // Modifier Dropdown Filtering
    $('#searchModifier_phrase2force').on('change', function () {
        var value = this.value;
        if (value === "(None)") {
            phrase2forceTable.column(3).search("^\\(None\\)|^$", true, false).draw(); // Match "(None)" explicitly or empty values
        } else {
            phrase2forceTable.column(3).search("^" + $.fn.dataTable.util.escapeRegex(value) + "$", true, false).draw();
        }
    });
    $('#searchModifier_force2phrase').on('change', function () {
        var value = this.value;
        if (value === "(None)") {
            force2phraseTable.column(3).search("^\\(None\\)|^$", true, false).draw(); // Match "(None)" explicitly or empty values
        } else {
            force2phraseTable.column(3).search("^" + $.fn.dataTable.util.escapeRegex(value) + "$", true, false).draw();
        }
    });

    // Direction Dropdown Filtering
    $('#searchDirection_phrase2force').on('change', function () {
        phrase2forceTable.column(4).search(this.value ? '^' + this.value + '$' : '', true, false).draw();
    });
    $('#searchDirection_force2phrase').on('change', function () {
        force2phraseTable.column(4).search(this.value ? '^' + this.value + '$' : '', true, false).draw();
    });

    // Event delegation for loading trial cards dynamically
    $(document).on("click", ".load-trial-card", function (e) {
        e.preventDefault();

        var trialType = $(this).data("type");
        var userId = $(this).data("user");
        var trialNumber = $(this).data("trial");
        var phraseText = $(this).data("phrase");
        var modifier = $(this).data("modifier");
        var direction = $(this).data("direction");

        // Remove any existing trial card
        $("#trialCardContainer").empty();

        // Determine file paths
        var videoPath, imagePath;
        if (trialType === "Phrase2Force") {
            imagePath = "/assets/images/translation_examples/" + userId + "_" + trialNumber + ".png";
        }
        // else {
        //     imagePath = "/assets/images/force_to_phrase_force_profiles/" + userId + "_" + trialNumber + ".png";
        // }

        // Generate trial card content dynamically
        var trialCardHtml = `
            <div class="data-section">
                <h3>User ${userId}, Trial ${trialNumber} (${trialType.replace("2", "-to-")})</h3>
                <p><strong>Phrase Text:</strong> ${phraseText}</p>
                <p><strong>Modifier:</strong> ${modifier}</p>
                <p><strong>Direction:</strong> ${direction}</p>
                <figure>
                    <p><strong>Translation Example:</strong></p>
                    <img src="${imagePath}" alt="Translation Example for User ${userId}, Trial ${trialNumber}" width="100%">
                </figure>
            </div>
        `;


        // Append new trial card
        $("#trialCardContainer").append(trialCardHtml);
        $('html, body').animate({
            scrollTop: $("#trialCardContainer").offset().top
        }, 500);
    });
});
</script>

<br>

<h3>Out-of-Distribution Modifiers</h3>
<p>The model successfully generalizes to unseen modifiers, with GloVe embeddings improving force profile reconstruction.</p>
<div class="image-grid">
    {% for image in site.static_files %}
        {% if image.path contains '/assets/images/out_of_distribution_modifier_results/' %}
            <figure>
                <img src="{{ site.baseurl }}{{ image.path }}" alt="Modifier Result">
                <figcaption></figcaption> <!-- Add caption if needed -->
            </figure>
        {% endif %}
    {% endfor %}
</div>

<br>

<h3>Out-of-Distribution Directions</h3>
<p>Our approach effectively handles unseen directional inputs, capturing force-language relationships even for novel movement directions.</p>
<div class="image-grid">
    {% for image in site.static_files %}
        {% if image.path contains '/assets/images/out_of_distribution_direction_results/' %}
            <figure>
                <img src="{{ site.baseurl }}{{ image.path }}" alt="Direction Result">
                <figcaption></figcaption>
            </figure>
        {% endif %}
    {% endfor %}
</div>

<style>
    .image-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr); /* Forces 3 columns */
        gap: 20px; /* Adjust spacing between images */
        justify-items: center;
        align-items: start;
        width: 100%;
    }

    .image-grid figure {
        margin: 0;
        text-align: center;
        width: 100%; /* Ensures figures fit inside grid */
    }

    .image-grid img {
        max-width: 100%; /* Ensures images resize correctly */
        height: auto;
        border-radius: 5px;
    }
</style>